apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kubernetes-cluster-health
  namespace: prometheus-stack
  labels:
    app.kubernetes.io/name: kube-prometheus-stack
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/managed-by: Helm
    prometheus: kube-prometheus-stack-prometheus
    role: alert-rules
spec:
  groups:
    # Kubernetes Cluster Health
    - name: kubernetes.cluster.health
      interval: 30s
      rules:
        - alert: KubernetesNodeNotReady
          expr: kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Kubernetes node {{ $labels.node }} is not ready"
            description: "Node {{ $labels.node }} has been not ready for more than 5 minutes."
        - alert: KubernetesPodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 15 > 0
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf \"%.2f\" $value }} times every 15 minutes."
        - alert: KubernetesPodNotReady
          expr: kube_pod_status_phase{phase=~"Pending|Unknown"} > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready"
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for more than 5 minutes."
    # Resource Usage Alerts
    - name: kubernetes.resources
      interval: 30s
      rules:
        - alert: NodeMemoryHighUsage
          expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.instance }} has high memory usage"
            description: "Node {{ $labels.instance }} memory usage is above 85% (current value: {{ printf \"%.2f\" $value }}%)"
        - alert: NodeDiskSpaceUsage
          expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 85
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.instance }} disk usage is high"
            description: "Node {{ $labels.instance }} disk usage on {{ $labels.mountpoint }} is above 85% (current value: {{ printf \"%.2f\" $value }}%)"
        - alert: NodeCPUHighUsage
          expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.instance }} has high CPU usage"
            description: "Node {{ $labels.instance }} CPU usage is above 90% (current value: {{ printf \"%.2f\" $value }}%)"
    # Custom Alert for High API Latency
    - name: kubernetes.api.latency
      interval: 5m
      rules:
        - alert: HighAPILatency
          expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="api"}[5m])) by (le)) > 0.5
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High API latency detected"
            description: "The 95th percentile latency for API requests is above 500ms."